{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4abef3ac-61be-40d8-9686-5f7bd3896068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:00:31.277850Z",
     "iopub.status.busy": "2025-10-15T17:00:31.277643Z",
     "iopub.status.idle": "2025-10-15T17:00:31.283551Z",
     "shell.execute_reply": "2025-10-15T17:00:31.282919Z",
     "shell.execute_reply.started": "2025-10-15T17:00:31.277829Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark-3.5.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006c1551-4bf9-4508-a664-f13550254006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:00:31.284494Z",
     "iopub.status.busy": "2025-10-15T17:00:31.284290Z",
     "iopub.status.idle": "2025-10-15T17:00:34.471936Z",
     "shell.execute_reply": "2025-10-15T17:00:34.471447Z",
     "shell.execute_reply.started": "2025-10-15T17:00:31.284474Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/16 01:00:32 WARN Utils: Your hostname, vm-debian resolves to a loopback address: 127.0.1.1; using 192.168.1.101 instead (on interface ens1)\n",
      "25/10/16 01:00:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/16 01:00:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('Test') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b446b7-28e9-4c7f-bc98-185f6a0a8f8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:00:34.473106Z",
     "iopub.status.busy": "2025-10-15T17:00:34.472797Z",
     "iopub.status.idle": "2025-10-15T17:00:35.931559Z",
     "shell.execute_reply": "2025-10-15T17:00:35.931043Z",
     "shell.execute_reply.started": "2025-10-15T17:00:34.473081Z"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('text').load('README.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab26f89-f78f-4f26-b794-3f50a08db1cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:00:35.932596Z",
     "iopub.status.busy": "2025-10-15T17:00:35.932352Z",
     "iopub.status.idle": "2025-10-15T17:00:37.980363Z",
     "shell.execute_reply": "2025-10-15T17:00:37.979726Z",
     "shell.execute_reply.started": "2025-10-15T17:00:35.932575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|        value|\n",
      "+-------------+\n",
      "|       123123|\n",
      "|         1111|\n",
      "|1111111111111|\n",
      "|             |\n",
      "|             |\n",
      "|  testtest111|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3eb71f-57b1-46d9-9e59-f521871b51d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:00:37.981272Z",
     "iopub.status.busy": "2025-10-15T17:00:37.981060Z",
     "iopub.status.idle": "2025-10-15T17:00:37.984637Z",
     "shell.execute_reply": "2025-10-15T17:00:37.984089Z",
     "shell.execute_reply.started": "2025-10-15T17:00:37.981251Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),  # True 表示字段可为null\n",
    "    StructField(\"age\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4298ebe-4235-4f29-969b-9f8e931382e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:00:37.986274Z",
     "iopub.status.busy": "2025-10-15T17:00:37.986056Z",
     "iopub.status.idle": "2025-10-15T17:00:38.041537Z",
     "shell.execute_reply": "2025-10-15T17:00:38.040977Z",
     "shell.execute_reply.started": "2025-10-15T17:00:37.986251Z"
    }
   },
   "outputs": [],
   "source": [
    "jsonDf = spark.read.schema(schema).option(\"multiLine\", True).format('json').load('./test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dfd08e9-65ee-4259-8235-ca521c2e8014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:00:38.042336Z",
     "iopub.status.busy": "2025-10-15T17:00:38.042144Z",
     "iopub.status.idle": "2025-10-15T17:00:38.254823Z",
     "shell.execute_reply": "2025-10-15T17:00:38.254300Z",
     "shell.execute_reply.started": "2025-10-15T17:00:38.042316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|mike| 20|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDf.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
